{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6qorvdQyq/bnB75UMfZB9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AISushilRaj/crosstl/blob/AISushilRaj-Chatbot--1/sushil_CrossGL_crosstl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To clone repository from crosstl"
      ],
      "metadata": {
        "id": "HlatqIbakyz-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8bUhZlxAZ57",
        "outputId": "c8012f79-2bc3-406b-b642-3ea944e65abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/crosstl\n"
          ]
        }
      ],
      "source": [
        "import git\n",
        "git.Repo.clone_from(\"https://github.com/AISushilRaj/crosstl.git\", \"crosstl\")\n",
        "\n",
        "%cd crosstl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -b sushil-crossgl"
      ],
      "metadata": {
        "id": "unHJp5HCMLrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c887cc9-2540-4cf3-80e0-2669adb802a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Switched to a new branch 'sushil-crossgl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Title: AI-Based Chatbot for Customer Support Automation**"
      ],
      "metadata": {
        "id": "sck7C2zUQjQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textinput = input(\"Enter a value: \")"
      ],
      "metadata": {
        "id": "N_4XGSC8NhmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc062a19-6789-4885-8a76-3aab0a4627c5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a value: The product is amazing and I absolutely love it! But the delivery service was horrible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(textinput)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mnlwCixYQ6Hn",
        "outputId": "e184007f-0255-461c-ac2f-484d32f9927c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The product is amazing and I absolutely love it! But the delivery service was horrible.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "import nltk\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.tree import Tree\n",
        "from nltk.corpus import wordnet\n",
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec, Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "DY7U6pmVTRqv"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMGjCZ9VTd6t",
        "outputId": "bb1054bb-b81c-42dd-85e8-5946aecdbfc5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = textinput"
      ],
      "metadata": {
        "id": "Fvx3fh_9Tiql"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwOCUgC7UqLx",
        "outputId": "335e3494-e97a-421c-d333-efda944ed4af"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(text)\n",
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "HkD26UrkTrqV"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Sentences:\", sentences)\n",
        "print(\"Words:\", words)\n",
        "\n",
        "# Stop words removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "print(\"Filtered Words:\", filtered_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r8AARWGVE0W",
        "outputId": "bf6fdf69-9d3b-448c-a2f4-130825bc25d4"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences: ['the delivery service was horrible']\n",
            "Words: ['the', 'delivery', 'service', 'was', 'horrible']\n",
            "Filtered Words: ['delivery', 'service', 'horrible']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "pos_tags = pos_tag(filtered_words)\n",
        "print(pos_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LuFwLnZVKNW",
        "outputId": "6c310470-3f9b-4fa7-c652-c24956ece1e8"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('delivery', 'NN'), ('service', 'NN'), ('horrible', 'NN')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Named Entity Recognition (NER)\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "\n",
        "named_entities = ne_chunk(pos_tags)\n",
        "print(\"Named Entities:\")\n",
        "for entity in named_entities:\n",
        "    if isinstance(entity, Tree):\n",
        "        print(entity)\n",
        "\n",
        "# Synonyms and Word Sense Disambiguation\n",
        "synonyms = set()\n",
        "for word in filtered_words:\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "\n",
        "print(\"Synonyms:\", synonyms)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tiy06lwWteL",
        "outputId": "a63bca26-8256-47a2-b6e9-ff8886404b85"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities:\n",
            "Synonyms: {'table_service', 'serving', 'saving', 'service', 'horrible', 'speech', 'frightful', 'deliverance', 'armed_service', 'horrifying', 'servicing', 'service_of_process', 'bringing', 'Robert_William_Service', 'religious_service', 'rescue', 'livery', 'obstetrical_delivery', 'pitch', 'manner_of_speaking', 'divine_service', 'delivery', 'inspection_and_repair', 'avail', 'serve', 'legal_transfer', 'atrocious', 'ugly', 'Service', 'overhaul', 'military_service', 'help'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of Words (BoW)\n",
        "vectorizer = CountVectorizer()\n",
        "X_bow = vectorizer.fit_transform([text])\n",
        "print(\"\\nBag of Words Representation:\")\n",
        "print(X_bow.toarray())\n",
        "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
        "\n",
        "# TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform([text])\n",
        "print(\"\\nTF-IDF Representation:\")\n",
        "print(X_tfidf.toarray())\n",
        "print(\"Feature Names:\", tfidf_vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo0V3h6BW-VX",
        "outputId": "7c9735f3-df8c-48da-9a5a-5cd21d3ddf97"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag of Words Representation:\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 2 1]]\n",
            "Feature Names: ['absolutely' 'amazing' 'and' 'but' 'delivery' 'horrible' 'is' 'it' 'love'\n",
            " 'product' 'service' 'the' 'was']\n",
            "\n",
            "TF-IDF Representation:\n",
            "[[0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.5  0.25]]\n",
            "Feature Names: ['absolutely' 'amazing' 'and' 'but' 'delivery' 'horrible' 'is' 'it' 'love'\n",
            " 'product' 'service' 'the' 'was']\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'text' is a list or Series of text data\n",
        "data = pd.DataFrame(vectorizer.get_feature_names_out())  # Create DataFrame with 'data' column\n",
        "\n",
        "# Calculate sentiment polarity and add it as a new column\n",
        "data['sentiment'] = data.apply(lambda text: TextBlob(str(text)).sentiment.polarity)\n",
        "\n",
        "# Print the DataFrame with the sentiment column\n",
        "print(data)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II9HN42Qaivy",
        "outputId": "7c29379d-5482-4611-d87f-359478dbb7df"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0  sentiment\n",
            "0  delivery       -1.0\n",
            "1  horrible        NaN\n",
            "2   service        NaN\n",
            "3       the        NaN\n",
            "4       was        NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**...... code starts.......**"
      ],
      "metadata": {
        "id": "5Gwl-ZRcyQK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "negative_response = \"Sorry for the bad service. Our customer care will call you back. You can also contact us at +91-100-100.\"\n",
        "positive_response =\"We are glad you had a great time.\"\n",
        "\n",
        "textinput = input(\"Enter a value: \") #.......................... (USE SUBSCRIBER to get data)\n",
        "text = textinput"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qPghOugXjgD",
        "outputId": "207d65fa-d539-400d-d4cb-ab147ce30604"
      },
      "execution_count": 175,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a value: The product is amazing and I absolutely love it! But the delivery service was horrible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The product is amazing and I absolutely love it! But the delivery service was horrible."
      ],
      "metadata": {
        "id": "WJfZTzyBhQm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of Words (BoW)\n",
        "vectorizer = CountVectorizer()\n",
        "X_bow = vectorizer.fit_transform([text])\n",
        "print(\"\\nBag of Words Representation:\")\n",
        "print(X_bow.toarray())\n",
        "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
        "\n",
        "\n",
        "def rate_word(word):\n",
        "   # \"\"\"Rates a word based on its sentiment polarity.\"\"\"\n",
        "    analysis = TextBlob(word)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "\n",
        "    if polarity < 0:\n",
        "        rating = \"Negative\"  # Bad feeling\n",
        "    elif polarity > 0:\n",
        "        rating = \"Positive\"\n",
        "    else:\n",
        "        rating = \"Neutral\"\n",
        "\n",
        "    return rating\n",
        "\n",
        "#vectorizer.get_feature_names_out()\n",
        "list_of_words = vectorizer.get_feature_names_out()\n",
        "print(list_of_words)\n",
        "# Example usage\n",
        "for word in list_of_words:\n",
        "    rating = rate_word(word)\n",
        "    if rating == \"Negative\":\n",
        "      print(f\"The word '{word}' has a {rating} sentiment.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZYoduBFwLgm",
        "outputId": "d33b8810-3dc3-4141-c3bb-373a79d7b96b"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag of Words Representation:\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 2 1]]\n",
            "Feature Names: ['absolutely' 'amazing' 'and' 'but' 'delivery' 'horrible' 'is' 'it' 'love'\n",
            " 'product' 'service' 'the' 'was']\n",
            "['absolutely' 'amazing' 'and' 'but' 'delivery' 'horrible' 'is' 'it' 'love'\n",
            " 'product' 'service' 'the' 'was']\n",
            "The word 'horrible' has a Negative sentiment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**now we got only negative words**"
      ],
      "metadata": {
        "id": "uROro8-Sx1YM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the above code is to know what the text is about"
      ],
      "metadata": {
        "id": "WIC8T1A3klN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below code is to give response**"
      ],
      "metadata": {
        "id": "F98dKT24ksXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "\n",
        "# Tokenize the text into sentences\n",
        "nltk.download('punkt')\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "# Define a negative sentiment response\n",
        "negative_response = \"Sorry for the bad service. Our customer care will call you back. You can also contact us at +91-100-100.\"\n",
        "positive_response =\"We are glad you had a great time.\"\n",
        "\n",
        "\n",
        "# Track if any negative sentiment is found\n",
        "negative_found = False\n",
        "\n",
        "# Analyze sentiment for each sentence\n",
        "for sentence in sentences:\n",
        "    blob = TextBlob(sentence)\n",
        "    sentiment_polarity = blob.sentiment.polarity\n",
        "    sentiment_label = \"Positive\" if sentiment_polarity > 0 else \"Negative\" if sentiment_polarity < 0 else \"Neutral\"\n",
        "\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Sentiment Polarity: {sentiment_polarity}\")\n",
        "    print(f\"Sentiment Label: {sentiment_label}\")\n",
        "\n",
        "    # If any sentence has negative sentiment, set the flag\n",
        "    if sentiment_label == \"Negative\":\n",
        "        negative_found = True\n",
        "        print(f\"Response: {negative_response}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Adjust the overall sentiment label logic\n",
        "if negative_found:\n",
        "    overall_label = \"Negative\"\n",
        "else:\n",
        "    overall_blob = TextBlob(text)\n",
        "    overall_sentiment = overall_blob.sentiment.polarity\n",
        "    overall_label = \"Positive\" if overall_sentiment > 0 else \"Neutral\"\n",
        "\n",
        "print(f\"Overall Sentiment Polarity: {overall_sentiment}\")\n",
        "print(f\"Overall Sentiment Label: {overall_label}\")\n",
        "\n",
        "print(\"......................................\")\n",
        "\n",
        "# Respond based on the presence of negative sentiment\n",
        "if negative_found:\n",
        "    print(f\"Response: {negative_response}\")\n",
        "else:\n",
        "    print({positive_response})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvgdR0Hdc0Hu",
        "outputId": "c30cd7f6-6a56-4c43-ef0a-11e8479ddd4f"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: The product is amazing and I absolutely love it!\n",
            "Sentiment Polarity: 0.6125\n",
            "Sentiment Label: Positive\n",
            "--------------------------------------------------\n",
            "Sentence: But the delivery service was horrible.\n",
            "Sentiment Polarity: -1.0\n",
            "Sentiment Label: Negative\n",
            "Response: Sorry for the bad service. Our customer care will call you back. You can also contact us at +91-100-100.\n",
            "--------------------------------------------------\n",
            "Overall Sentiment Polarity: 0.55\n",
            "Overall Sentiment Label: Negative\n",
            "......................................\n",
            "Response: Sorry for the bad service. Our customer care will call you back. You can also contact us at +91-100-100.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(text)\n",
        "if overall_label == \"Positive\":\n",
        "    print(\"\\n\",\"The overall sentiment is positive.\")\n",
        "    #....................................(use PUBLISHER )\n",
        "    print(positive_response)\n",
        "\n",
        "elif overall_label == \"Negative\":\n",
        "    print(\"\\n\",\"The overall sentiment is negative.\")\n",
        "    #....................................(use PUBLISHER )\n",
        "    print(\"\\n\",negative_response)\n",
        "else:\n",
        "    print(\"The overall sentiment is neutral.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "7ymByEsodqer",
        "outputId": "0b5e35e2-f254-4a44-ba16-7f61421efa4a"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The product is amazing and I absolutely love it! But the delivery service was horrible.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " The overall sentiment is negative.\n",
            "\n",
            " Sorry for the bad service. Our customer care will call you back. You can also contact us at +91-100-100.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**to test..............................**"
      ],
      "metadata": {
        "id": "hubyQ_UjytLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!git add ."
      ],
      "metadata": {
        "id": "VF9C9vYu2wun"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!git config --global user.name \"AISushilRaj\"\n",
        "#!git config --global user.email \"aisushilraj@gmail.com\""
      ],
      "metadata": {
        "id": "OcKPJkdn5oxs"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "source": [
        "#!git remote add origin https://github.com/AISushilRaj/crosstl.git\n",
        "#!git remote rename origin old-origin"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "SnbDX_ek59fI"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "source": [
        "#!git checkout -b AISushilRaj-crosstl"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgwhOhrT6BnW",
        "outputId": "c4ee758d-cc63-4035-9cd2-55fcf1797628"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Switched to a new branch 'AISushilRaj-crosstl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git add ."
      ],
      "metadata": {
        "id": "ZNZlgwZY6ofL"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #!git commit -m \"Text Input Handling:\"\n",
        "\n",
        "# \"The program accepts user input using input(). The user enters a sentence or paragraph that is analyzed for sentiment.\"\n",
        "# \"Bag of Words (BoW) Representation:\"\n",
        "# \"The text is tokenized into individual words.\"\n",
        "# \"A Bag of Words model is created using CountVectorizer(), which counts the frequency of each unique word in the text.\"\n",
        "# \"The resulting matrix (word counts) and feature names (unique words) are displayed.\"\n",
        "# \"Word Sentiment Rating:\"\n",
        "\n",
        "# \"Each word from the Bag of Words feature set is analyzed using the TextBlob library to calculate its sentiment polarity.\"\n",
        "# \"Based on polarity:\"\n",
        "# \"Positive: Polarity > 0\"\n",
        "# \"Negative: Polarity < 0\"\n",
        "# \"Neutral: Polarity = 0\"\n",
        "# \"Words with negative polarity are flagged, and their sentiment is printed.\"\n",
        "# \"Sentence-Level Sentiment Analysis:\"\n",
        "\n",
        "# \"The input text is split into individual sentences.\"\n",
        "# \"Each sentence is analyzed for sentiment using TextBlob:\"\n",
        "# \"Positive: Polarity > 0\"\n",
        "# \"Negative: Polarity < 0\"\n",
        "# \"Neutral: Polarity = 0\"\n",
        "# \"If a sentence has a negative sentiment, a predefined negative response is triggered.\"\n",
        "# \"Overall Sentiment Analysis:\"\n",
        "\n",
        "# \"The overall sentiment polarity is calculated by analyzing the entire input text as a single unit.\"\n",
        "# \"If any sentence was flagged as negative earlier, the overall sentiment is overridden as Negative. Otherwise, it is determined by the calculated polarity:\"\n",
        "# \"Positive: Polarity > 0\"\n",
        "# \"Neutral: Polarity = 0\"\n",
        "# \"Response Generation:\"\n",
        "\n",
        "# \"Based on the overall sentiment:\"\n",
        "# \"Positive Sentiment: Displays a predefined positive response.\"\n",
        "# \"Negative Sentiment: Displays a predefined negative response.\"\n",
        "# \"Neutral Sentiment: Indicates that the text is neutral.\"\n",
        "# \"Execution Example:\"\n",
        "\n",
        "# \"Input: The product is amazing and I absolutely love it! But the delivery service was horrible.\"\n",
        "# \"Output:\"\n",
        "# \"Sentence 1: Positive (Polarity: 0.6125)\"\n",
        "# \"Sentence 2: Negative (Polarity: -1.0)\"\n",
        "# \"Overall: Negative (overridden due to the negative sentence)\"\n",
        "# \"Response:Sorry for the bad service. Our customer care will call you back\""
      ],
      "metadata": {
        "id": "amqfDfE929OD"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git fetch origin target-branch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj3fPYny79si",
        "outputId": "18c7089a-df66-461e-a23f-eb855af39f89"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: 'origin' does not appear to be a git repository\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AISushilRaj/crosstl.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMUUuWkH7-ed",
        "outputId": "025276bb-8818-4f2e-f02d-503c5008027c"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'crosstl' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -b AISushilRaj-Chatbot--1 origin/AISushilRaj-Chatbot--1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWXcyT-48QPb",
        "outputId": "aec39ed2-44a2-4a72-de35-93ee16ecb6a1"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: 'origin/AISushilRaj-Chatbot--1' is not a commit and a branch 'AISushilRaj-Chatbot--1' cannot be created from it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git fetch --all\n",
        "!git branch -r\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a05aIyXA8XAM",
        "outputId": "15887ba9-37cd-4c77-8444-e9aff9e583a3"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching old-origin\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 1), reused 1 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (3/3), 1.79 KiB | 1.79 MiB/s, done.\n",
            "From https://github.com/AISushilRaj/crosstl\n",
            " * [new branch]      AISushilRaj-Chatbot--1 -> old-origin/AISushilRaj-Chatbot--1\n",
            "  \u001b[31mold-origin/AISushilRaj-Chatbot--1\u001b[m\n",
            "  \u001b[31mold-origin/HEAD\u001b[m -> old-origin/main\n",
            "  \u001b[31mold-origin/main\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -b AISushilRaj-Chatbot--1 old-origin/AISushilRaj-Chatbot--1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPsE-qX98goV",
        "outputId": "9508e08b-cb34-444b-cf2c-fc60dd25f7dc"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'AISushilRaj-Chatbot--1' set up to track remote branch 'AISushilRaj-Chatbot--1' from 'old-origin'.\n",
            "Switched to a new branch 'AISushilRaj-Chatbot--1'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin AISushilRaj-Chatbot--1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzT0vgZp8qqp",
        "outputId": "e8650b8a-c6fb-4607-bbaf-f35f0163a625"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote -v\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8x8qmGE8uZc",
        "outputId": "234f941a-05f6-4bf3-ed61-88a278053d4e"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "old-origin\thttps://github.com/AISushilRaj/crosstl.git (fetch)\n",
            "old-origin\thttps://github.com/AISushilRaj/crosstl.git (push)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add origin https://github.com/AISushilRaj/crosstl.git\n"
      ],
      "metadata": {
        "id": "CQ3ORLI081c1"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote set-url origin https://github.com/AISushilRaj/crosstl.git\n"
      ],
      "metadata": {
        "id": "qyVs5ITP85xD"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin AISushilRaj-Chatbot--1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riqliurG89Ug",
        "outputId": "3f66387f-77f2-4af6-df06-900d3be3230c"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install JupyterLab Git extension\n",
        "!pip install jupyterlab-git\n",
        "\n",
        "# Enable Git extension in JupyterLab\n",
        "!jupyter serverextension enable --py jupyterlab_git\n",
        "\n",
        "# Restart JupyterLab\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRzxPQwY9AeC",
        "outputId": "d5355919-3e82-4d5d-ea6d-d1da52ad8862"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jupyterlab-git\n",
            "  Downloading jupyterlab_git-0.50.2-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting jupyter-server<3,>=2.0.1 (from jupyterlab-git)\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting nbdime~=4.0.1 (from jupyterlab-git)\n",
            "  Downloading nbdime-4.0.2-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from jupyterlab-git) (5.10.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from jupyterlab-git) (24.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.10/dist-packages (from jupyterlab-git) (4.9.0)\n",
            "Requirement already satisfied: traitlets~=5.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-git) (5.7.1)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-git) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-git) (23.1.0)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-git) (3.1.5)\n",
            "Collecting jupyter-client>=7.4.4 (from jupyter-server<3,>=2.0.1->jupyterlab-git)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-git) (5.7.2)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.0.1->jupyterlab-git)\n",
            "  Downloading jupyter_events-0.11.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.0.1->jupyterlab-git)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-git) (7.16.5)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.0.1->jupyterlab-git)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-git) (0.21.1)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-git) (24.0.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-git) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-git) (0.18.1)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-git) (6.3.3)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-git) (1.8.0)\n",
            "Collecting colorama (from nbdime~=4.0.1->jupyterlab-git)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: gitpython!=2.1.4,!=2.1.5,!=2.1.6 in /usr/local/lib/python3.10/dist-packages (from nbdime~=4.0.1->jupyterlab-git) (3.1.44)\n",
            "Collecting jupyter-server-mathjax>=0.2.2 (from nbdime~=4.0.1->jupyterlab-git)\n",
            "  Downloading jupyter_server_mathjax-0.2.6-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from nbdime~=4.0.1->jupyterlab-git) (2.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nbdime~=4.0.1->jupyterlab-git) (2.32.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->jupyterlab-git) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->jupyterlab-git) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect->jupyterlab-git) (0.7.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.0.1->jupyterlab-git) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.0.1->jupyterlab-git) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.0.1->jupyterlab-git) (1.2.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.0.1->jupyterlab-git) (21.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=2.1.4,!=2.1.5,!=2.1.6->nbdime~=4.0.1->jupyterlab-git) (4.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.0.1->jupyterlab-git) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->jupyterlab-git) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->jupyterlab-git) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->jupyterlab-git) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->jupyterlab-git) (0.22.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.0.1->jupyterlab-git) (4.3.6)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.0.1->jupyterlab-git)\n",
            "  Downloading python_json_logger-3.2.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.0.1->jupyterlab-git) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.0.1->jupyterlab-git)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.0.1->jupyterlab-git)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (3.1.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (1.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nbdime~=4.0.1->jupyterlab-git) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nbdime~=4.0.1->jupyterlab-git) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nbdime~=4.0.1->jupyterlab-git) (2024.12.14)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (1.4.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=2.1.4,!=2.1.5,!=2.1.6->nbdime~=4.0.1->jupyterlab-git) (5.0.2)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.0.1->jupyterlab-git)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.0.1->jupyterlab-git)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.0.1->jupyterlab-git) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.0.1->jupyterlab-git)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.0.1->jupyterlab-git) (24.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from mistune<4,>=2.0.3->nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.0.1->jupyterlab-git) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-git) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.0.1->jupyterlab-git) (2.22)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.0.1->jupyterlab-git)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.0.1->jupyterlab-git)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading jupyterlab_git-0.50.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nbdime-4.0.2-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_events-0.11.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_mathjax-0.2.6-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading python_json_logger-3.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, fqdn, colorama, jupyter-server-terminals, jupyter-client, arrow, isoduration, jupyter-events, jupyter-server, jupyter-server-mathjax, nbdime, jupyterlab-git\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.3.0 colorama-0.4.6 fqdn-1.5.1 isoduration-20.11.0 jupyter-client-8.6.3 jupyter-events-0.11.0 jupyter-server-2.15.0 jupyter-server-mathjax-0.2.6 jupyter-server-terminals-0.5.3 jupyterlab-git-0.50.2 nbdime-4.0.2 overrides-7.7.0 python-json-logger-3.2.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/jupyter-serverextension\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jupyter_core/application.py\", line 283, in launch_instance\n",
            "    super().launch_instance(argv=argv, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/notebook/serverextensions.py\", line 289, in start\n",
            "    super().start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jupyter_core/application.py\", line 270, in start\n",
            "    self.subapp.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/notebook/serverextensions.py\", line 208, in start\n",
            "    self.toggle_server_extension_python(arg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/notebook/serverextensions.py\", line 197, in toggle_server_extension_python\n",
            "    m, server_exts = _get_server_extension_metadata(package)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/notebook/serverextensions.py\", line 325, in _get_server_extension_metadata\n",
            "    raise KeyError(f'The Python module {module} does not include any valid server extensions')\n",
            "KeyError: 'The Python module jupyterlab_git does not include any valid server extensions'\n"
          ]
        }
      ]
    }
  ]
}