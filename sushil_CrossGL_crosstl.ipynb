{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHoXO5ergwtLEBTY11QftL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AISushilRaj/crosstl/blob/AISushilRaj-Chatbot--1/sushil_CrossGL_crosstl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To clone repository from crosstl"
      ],
      "metadata": {
        "id": "HlatqIbakyz-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8bUhZlxAZ57",
        "outputId": "c8012f79-2bc3-406b-b642-3ea944e65abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/crosstl\n"
          ]
        }
      ],
      "source": [
        "import git\n",
        "git.Repo.clone_from(\"https://github.com/AISushilRaj/crosstl.git\", \"crosstl\")\n",
        "\n",
        "%cd crosstl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -b sushil-crossgl"
      ],
      "metadata": {
        "id": "unHJp5HCMLrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c887cc9-2540-4cf3-80e0-2669adb802a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Switched to a new branch 'sushil-crossgl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Title: AI-Based Chatbot for Customer Support Automation**"
      ],
      "metadata": {
        "id": "sck7C2zUQjQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textinput = input(\"Enter a value: \")"
      ],
      "metadata": {
        "id": "N_4XGSC8NhmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc062a19-6789-4885-8a76-3aab0a4627c5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a value: The product is amazing and I absolutely love it! But the delivery service was horrible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(textinput)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mnlwCixYQ6Hn",
        "outputId": "e184007f-0255-461c-ac2f-484d32f9927c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The product is amazing and I absolutely love it! But the delivery service was horrible.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "import nltk\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.tree import Tree\n",
        "from nltk.corpus import wordnet\n",
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec, Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "DY7U6pmVTRqv"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMGjCZ9VTd6t",
        "outputId": "bb1054bb-b81c-42dd-85e8-5946aecdbfc5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = textinput"
      ],
      "metadata": {
        "id": "Fvx3fh_9Tiql"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwOCUgC7UqLx",
        "outputId": "335e3494-e97a-421c-d333-efda944ed4af"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(text)\n",
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "HkD26UrkTrqV"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Sentences:\", sentences)\n",
        "print(\"Words:\", words)\n",
        "\n",
        "# Stop words removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "print(\"Filtered Words:\", filtered_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r8AARWGVE0W",
        "outputId": "bf6fdf69-9d3b-448c-a2f4-130825bc25d4"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences: ['the delivery service was horrible']\n",
            "Words: ['the', 'delivery', 'service', 'was', 'horrible']\n",
            "Filtered Words: ['delivery', 'service', 'horrible']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "pos_tags = pos_tag(filtered_words)\n",
        "print(pos_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LuFwLnZVKNW",
        "outputId": "6c310470-3f9b-4fa7-c652-c24956ece1e8"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('delivery', 'NN'), ('service', 'NN'), ('horrible', 'NN')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Named Entity Recognition (NER)\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "\n",
        "named_entities = ne_chunk(pos_tags)\n",
        "print(\"Named Entities:\")\n",
        "for entity in named_entities:\n",
        "    if isinstance(entity, Tree):\n",
        "        print(entity)\n",
        "\n",
        "# Synonyms and Word Sense Disambiguation\n",
        "synonyms = set()\n",
        "for word in filtered_words:\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "\n",
        "print(\"Synonyms:\", synonyms)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tiy06lwWteL",
        "outputId": "a63bca26-8256-47a2-b6e9-ff8886404b85"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities:\n",
            "Synonyms: {'table_service', 'serving', 'saving', 'service', 'horrible', 'speech', 'frightful', 'deliverance', 'armed_service', 'horrifying', 'servicing', 'service_of_process', 'bringing', 'Robert_William_Service', 'religious_service', 'rescue', 'livery', 'obstetrical_delivery', 'pitch', 'manner_of_speaking', 'divine_service', 'delivery', 'inspection_and_repair', 'avail', 'serve', 'legal_transfer', 'atrocious', 'ugly', 'Service', 'overhaul', 'military_service', 'help'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of Words (BoW)\n",
        "vectorizer = CountVectorizer()\n",
        "X_bow = vectorizer.fit_transform([text])\n",
        "print(\"\\nBag of Words Representation:\")\n",
        "print(X_bow.toarray())\n",
        "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
        "\n",
        "# TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform([text])\n",
        "print(\"\\nTF-IDF Representation:\")\n",
        "print(X_tfidf.toarray())\n",
        "print(\"Feature Names:\", tfidf_vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo0V3h6BW-VX",
        "outputId": "7c9735f3-df8c-48da-9a5a-5cd21d3ddf97"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag of Words Representation:\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 2 1]]\n",
            "Feature Names: ['absolutely' 'amazing' 'and' 'but' 'delivery' 'horrible' 'is' 'it' 'love'\n",
            " 'product' 'service' 'the' 'was']\n",
            "\n",
            "TF-IDF Representation:\n",
            "[[0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.5  0.25]]\n",
            "Feature Names: ['absolutely' 'amazing' 'and' 'but' 'delivery' 'horrible' 'is' 'it' 'love'\n",
            " 'product' 'service' 'the' 'was']\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'text' is a list or Series of text data\n",
        "data = pd.DataFrame(vectorizer.get_feature_names_out())  # Create DataFrame with 'data' column\n",
        "\n",
        "# Calculate sentiment polarity and add it as a new column\n",
        "data['sentiment'] = data.apply(lambda text: TextBlob(str(text)).sentiment.polarity)\n",
        "\n",
        "# Print the DataFrame with the sentiment column\n",
        "print(data)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II9HN42Qaivy",
        "outputId": "7c29379d-5482-4611-d87f-359478dbb7df"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0  sentiment\n",
            "0  delivery       -1.0\n",
            "1  horrible        NaN\n",
            "2   service        NaN\n",
            "3       the        NaN\n",
            "4       was        NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**...... code starts.......**"
      ],
      "metadata": {
        "id": "5Gwl-ZRcyQK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "negative_response = \"Sorry for the bad service. Our customer care will call you back. You can also contact us at +91-100-100.\"\n",
        "positive_response =\"We are glad you had a great time.\"\n",
        "\n",
        "textinput = input(\"Enter a value: \") #.......................... (USE SUBSCRIBER to get data)\n",
        "text = textinput"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qPghOugXjgD",
        "outputId": "207d65fa-d539-400d-d4cb-ab147ce30604"
      },
      "execution_count": 175,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a value: The product is amazing and I absolutely love it! But the delivery service was horrible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The product is amazing and I absolutely love it! But the delivery service was horrible."
      ],
      "metadata": {
        "id": "WJfZTzyBhQm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of Words (BoW)\n",
        "vectorizer = CountVectorizer()\n",
        "X_bow = vectorizer.fit_transform([text])\n",
        "print(\"\\nBag of Words Representation:\")\n",
        "print(X_bow.toarray())\n",
        "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
        "\n",
        "\n",
        "def rate_word(word):\n",
        "   # \"\"\"Rates a word based on its sentiment polarity.\"\"\"\n",
        "    analysis = TextBlob(word)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "\n",
        "    if polarity < 0:\n",
        "        rating = \"Negative\"  # Bad feeling\n",
        "    elif polarity > 0:\n",
        "        rating = \"Positive\"\n",
        "    else:\n",
        "        rating = \"Neutral\"\n",
        "\n",
        "    return rating\n",
        "\n",
        "#vectorizer.get_feature_names_out()\n",
        "list_of_words = vectorizer.get_feature_names_out()\n",
        "print(list_of_words)\n",
        "# Example usage\n",
        "for word in list_of_words:\n",
        "    rating = rate_word(word)\n",
        "    if rating == \"Negative\":\n",
        "      print(f\"The word '{word}' has a {rating} sentiment.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZYoduBFwLgm",
        "outputId": "d33b8810-3dc3-4141-c3bb-373a79d7b96b"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag of Words Representation:\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 2 1]]\n",
            "Feature Names: ['absolutely' 'amazing' 'and' 'but' 'delivery' 'horrible' 'is' 'it' 'love'\n",
            " 'product' 'service' 'the' 'was']\n",
            "['absolutely' 'amazing' 'and' 'but' 'delivery' 'horrible' 'is' 'it' 'love'\n",
            " 'product' 'service' 'the' 'was']\n",
            "The word 'horrible' has a Negative sentiment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**now we got only negative words**"
      ],
      "metadata": {
        "id": "uROro8-Sx1YM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the above code is to know what the text is about"
      ],
      "metadata": {
        "id": "WIC8T1A3klN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below code is to give response**"
      ],
      "metadata": {
        "id": "F98dKT24ksXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "\n",
        "# Tokenize the text into sentences\n",
        "nltk.download('punkt')\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "# Define a negative sentiment response\n",
        "negative_response = \"Sorry for the bad service. Our customer care will call you back. You can also contact us at +91-100-100.\"\n",
        "positive_response =\"We are glad you had a great time.\"\n",
        "\n",
        "\n",
        "# Track if any negative sentiment is found\n",
        "negative_found = False\n",
        "\n",
        "# Analyze sentiment for each sentence\n",
        "for sentence in sentences:\n",
        "    blob = TextBlob(sentence)\n",
        "    sentiment_polarity = blob.sentiment.polarity\n",
        "    sentiment_label = \"Positive\" if sentiment_polarity > 0 else \"Negative\" if sentiment_polarity < 0 else \"Neutral\"\n",
        "\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Sentiment Polarity: {sentiment_polarity}\")\n",
        "    print(f\"Sentiment Label: {sentiment_label}\")\n",
        "\n",
        "    # If any sentence has negative sentiment, set the flag\n",
        "    if sentiment_label == \"Negative\":\n",
        "        negative_found = True\n",
        "        print(f\"Response: {negative_response}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Adjust the overall sentiment label logic\n",
        "if negative_found:\n",
        "    overall_label = \"Negative\"\n",
        "else:\n",
        "    overall_blob = TextBlob(text)\n",
        "    overall_sentiment = overall_blob.sentiment.polarity\n",
        "    overall_label = \"Positive\" if overall_sentiment > 0 else \"Neutral\"\n",
        "\n",
        "print(f\"Overall Sentiment Polarity: {overall_sentiment}\")\n",
        "print(f\"Overall Sentiment Label: {overall_label}\")\n",
        "\n",
        "print(\"......................................\")\n",
        "\n",
        "# Respond based on the presence of negative sentiment\n",
        "if negative_found:\n",
        "    print(f\"Response: {negative_response}\")\n",
        "else:\n",
        "    print({positive_response})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvgdR0Hdc0Hu",
        "outputId": "c30cd7f6-6a56-4c43-ef0a-11e8479ddd4f"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: The product is amazing and I absolutely love it!\n",
            "Sentiment Polarity: 0.6125\n",
            "Sentiment Label: Positive\n",
            "--------------------------------------------------\n",
            "Sentence: But the delivery service was horrible.\n",
            "Sentiment Polarity: -1.0\n",
            "Sentiment Label: Negative\n",
            "Response: Sorry for the bad service. Our customer care will call you back. You can also contact us at +91-100-100.\n",
            "--------------------------------------------------\n",
            "Overall Sentiment Polarity: 0.55\n",
            "Overall Sentiment Label: Negative\n",
            "......................................\n",
            "Response: Sorry for the bad service. Our customer care will call you back. You can also contact us at +91-100-100.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(text)\n",
        "if overall_label == \"Positive\":\n",
        "    print(\"\\n\",\"The overall sentiment is positive.\")\n",
        "    #....................................(use PUBLISHER )\n",
        "    print(positive_response)\n",
        "\n",
        "elif overall_label == \"Negative\":\n",
        "    print(\"\\n\",\"The overall sentiment is negative.\")\n",
        "    #....................................(use PUBLISHER )\n",
        "    print(\"\\n\",negative_response)\n",
        "else:\n",
        "    print(\"The overall sentiment is neutral.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "7ymByEsodqer",
        "outputId": "0b5e35e2-f254-4a44-ba16-7f61421efa4a"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The product is amazing and I absolutely love it! But the delivery service was horrible.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " The overall sentiment is negative.\n",
            "\n",
            " Sorry for the bad service. Our customer care will call you back. You can also contact us at +91-100-100.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hubyQ_UjytLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #!git commit -m \"Text Input Handling:\"\n",
        "\n",
        "# \"The program accepts user input using input(). The user enters a sentence or paragraph that is analyzed for sentiment.\"\n",
        "# \"Bag of Words (BoW) Representation:\"\n",
        "# \"The text is tokenized into individual words.\"\n",
        "# \"A Bag of Words model is created using CountVectorizer(), which counts the frequency of each unique word in the text.\"\n",
        "# \"The resulting matrix (word counts) and feature names (unique words) are displayed.\"\n",
        "# \"Word Sentiment Rating:\"\n",
        "\n",
        "# \"Each word from the Bag of Words feature set is analyzed using the TextBlob library to calculate its sentiment polarity.\"\n",
        "# \"Based on polarity:\"\n",
        "# \"Positive: Polarity > 0\"\n",
        "# \"Negative: Polarity < 0\"\n",
        "# \"Neutral: Polarity = 0\"\n",
        "# \"Words with negative polarity are flagged, and their sentiment is printed.\"\n",
        "# \"Sentence-Level Sentiment Analysis:\"\n",
        "\n",
        "# \"The input text is split into individual sentences.\"\n",
        "# \"Each sentence is analyzed for sentiment using TextBlob:\"\n",
        "# \"Positive: Polarity > 0\"\n",
        "# \"Negative: Polarity < 0\"\n",
        "# \"Neutral: Polarity = 0\"\n",
        "# \"If a sentence has a negative sentiment, a predefined negative response is triggered.\"\n",
        "# \"Overall Sentiment Analysis:\"\n",
        "\n",
        "# \"The overall sentiment polarity is calculated by analyzing the entire input text as a single unit.\"\n",
        "# \"If any sentence was flagged as negative earlier, the overall sentiment is overridden as Negative. Otherwise, it is determined by the calculated polarity:\"\n",
        "# \"Positive: Polarity > 0\"\n",
        "# \"Neutral: Polarity = 0\"\n",
        "# \"Response Generation:\"\n",
        "\n",
        "# \"Based on the overall sentiment:\"\n",
        "# \"Positive Sentiment: Displays a predefined positive response.\"\n",
        "# \"Negative Sentiment: Displays a predefined negative response.\"\n",
        "# \"Neutral Sentiment: Indicates that the text is neutral.\"\n",
        "# \"Execution Example:\"\n",
        "\n",
        "# \"Input: The product is amazing and I absolutely love it! But the delivery service was horrible.\"\n",
        "# \"Output:\"\n",
        "# \"Sentence 1: Positive (Polarity: 0.6125)\"\n",
        "# \"Sentence 2: Negative (Polarity: -1.0)\"\n",
        "# \"Overall: Negative (overridden due to the negative sentence)\"\n",
        "# \"Response:Sorry for the bad service. Our customer care will call you back\""
      ],
      "metadata": {
        "id": "amqfDfE929OD"
      },
      "execution_count": 173,
      "outputs": []
    }
  ]
}